{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import data from Kaggle using API\n",
        "## Click-Through Rate Prediction :\n",
        "Air pollution causes approximately 7 million premature deaths annually (WHO). This dataset enables researchers and data scientists to:\n",
        "\n",
        "Analyze global pollution disparities\n",
        "Investigate health impacts of air quality\n",
        "Develop predictive models for environmental monitoring\n",
        "\n",
        " Data Link : https://www.kaggle.com/datasets/youssefelebiary/air-quality-2024/data\n"
      ],
      "metadata": {
        "id": "tf5M5ISvMYoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "sklf-AMbM6mp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d youssefelebiary/air-quality-2024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgsNtWEKNPGh",
        "outputId": "99b0a575-d052-4d30-e2ed-f9bc18fa4cb1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/youssefelebiary/air-quality-2024\n",
            "License(s): MIT\n",
            "Downloading air-quality-2024.zip to /content\n",
            "  0% 0.00/1.76M [00:00<?, ?B/s]\n",
            "100% 1.76M/1.76M [00:00<00:00, 197MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip air-quality-2024.zip -d air_quality"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFVnfIq-URta",
        "outputId": "e49365ab-6489-4c8a-e8b4-1ea51e2a5d64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  air-quality-2024.zip\n",
            "  inflating: air_quality/Air_Quality.csv  \n",
            "  inflating: air_quality/Brasilia_Air_Quality.csv  \n",
            "  inflating: air_quality/Cairo_Air_Quality.csv  \n",
            "  inflating: air_quality/Dubai_Air_Quality.csv  \n",
            "  inflating: air_quality/London_Air_Quality.csv  \n",
            "  inflating: air_quality/New_York_Air_Quality.csv  \n",
            "  inflating: air_quality/Sydney_Air_Quality.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install pyspark lib"
      ],
      "metadata": {
        "id": "n45m9yT8Ue5g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH8cTQKsRxUy",
        "outputId": "d0851a12-f6f3-4f06-b243-e4d33b2d7961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark py4j\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import time\n"
      ],
      "metadata": {
        "id": "xvPlTNZ5MUVH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"AirQuality\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "OR0zvUV7MhAu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_df = pd.read_csv(\"/content/air_quality/Air_Quality.csv\")\n",
        "spark_df = spark.read.csv(\"/content/air_quality/Air_Quality.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "wSIggwied_Y6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXtoa3tMX1Ya",
        "outputId": "235dcb4b-8e12-432d-c51e-9db5ec66899d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date', 'City', 'CO', 'CO2', 'NO2', 'SO2', 'O3', 'PM2.5', 'PM10',\n",
              "       'AQI'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_df.rename(columns={\"PM2.5\": \"PM2_5\"}, inplace=True)\n",
        "spark_df = spark_df.withColumnRenamed(\"PM2.5\", \"PM2_5\")"
      ],
      "metadata": {
        "id": "H0cum8hOis0D"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Pandas library"
      ],
      "metadata": {
        "id": "bCxc8IHIf6cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pollutants = [\"CO\", \"CO2\", \"NO2\", \"SO2\", \"O3\", \"PM2_5\", \"PM10\", \"AQI\"]\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "pandas_stats = (\n",
        "    pandas_df.groupby(\"City\")[pollutants]\n",
        "    .agg([\"mean\", lambda x: x.quantile(0.25), \"median\", lambda x: x.quantile(0.75)])\n",
        ")\n",
        "\n",
        "# Rename columns: pollutant_mean, pollutant_q25, ...\n",
        "pandas_stats.columns = [\n",
        "    f\"{col[0]}_{col[1] if isinstance(col[1], str) else 'q25' if col[1]==0.25 else 'q75'}\"\n",
        "    for col in pandas_stats.columns\n",
        "]\n",
        "pandas_stats = pandas_stats.reset_index()\n",
        "\n",
        "end = time.time()\n",
        "print(\"✅ Pandas Stats:\")\n",
        "print(pandas_stats.head())\n",
        "print(f\"⏱ Pandas Time: {end - start:.4f} seconds\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "clecmDUyfKA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb0f3ae-13a9-45a0-e8a7-3344ec7e7825"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pandas Stats:\n",
            "       City     CO_mean  CO_<lambda_0>  CO_median  CO_<lambda_1>    CO2_mean  \\\n",
            "0  Brasilia  221.450478          147.0      192.0          267.0  445.726368   \n",
            "1     Cairo  293.819217          198.0      239.0          316.0  457.920398   \n",
            "2     Dubai  440.464026          305.0      400.0          533.0  463.778607   \n",
            "3    London  187.744194          156.0      177.0          205.0  475.114428   \n",
            "4  New York  283.640027          207.0      248.0          313.0  488.358831   \n",
            "\n",
            "   CO2_<lambda_0>  CO2_median  CO2_<lambda_1>   NO2_mean  ...  PM2_5_median  \\\n",
            "0           440.0       444.0           450.0   8.735633  ...           5.3   \n",
            "1           449.0       454.0           462.0  32.617634  ...          20.7   \n",
            "2           452.0       461.0           473.0  39.488297  ...          39.2   \n",
            "3           450.0       458.0           482.0  21.797495  ...           7.8   \n",
            "4           457.0       471.0           494.0  27.804360  ...          11.2   \n",
            "\n",
            "   PM2_5_<lambda_1>   PM10_mean  PM10_<lambda_0>  PM10_median  \\\n",
            "0               8.5    8.886726            4.600          7.3   \n",
            "1              28.3   43.422222           26.200         34.9   \n",
            "2              52.0  111.040619           58.775         89.2   \n",
            "3              12.5   14.136009            8.700         11.9   \n",
            "4              17.5   18.948406           10.000         16.1   \n",
            "\n",
            "   PM10_<lambda_1>   AQI_mean  AQI_<lambda_0>  AQI_median  AQI_<lambda_1>  \n",
            "0           11.500  24.749358       16.800000   22.983334       30.800000  \n",
            "1           49.300  52.489745       38.441665   51.658328       62.874998  \n",
            "2          143.525  85.113722       67.309584   78.119163       98.883330  \n",
            "3           17.100  27.097212       20.800000   25.200000       30.341665  \n",
            "4           25.300  32.878247       23.600002   29.200000       37.600000  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "⏱ Pandas Time: 0.1112 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Pyspark\n"
      ],
      "metadata": {
        "id": "AeWy2SYZheLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.groupBy(\"City\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHLOfAw3VA5C",
        "outputId": "0ade65f0-b2cf-4c4d-d452-1c9b3dfbf23f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|    City|count|\n",
            "+--------+-----+\n",
            "|   Cairo| 8784|\n",
            "|  London| 8784|\n",
            "|  Sydney| 8784|\n",
            "|Brasilia| 8784|\n",
            "|   Dubai| 8784|\n",
            "|New York| 8784|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean, percentile_approx\n",
        "import time\n",
        "\n",
        "# Rename columns like \"PM2.5\" to \"PM2_5\" for Spark compatibility\n",
        "pollutants = [\"CO\", \"CO2\", \"NO2\", \"SO2\", \"O3\", \"PM2.5\", \"PM10\", \"AQI\"]\n",
        "rename_map = {col: col.replace(\".\", \"_\") for col in pollutants}\n",
        "\n",
        "# Apply renaming\n",
        "for old_name, new_name in rename_map.items():\n",
        "    spark_df = spark_df.withColumnRenamed(old_name, new_name)\n",
        "\n",
        "# Updated pollutant names (for renamed columns)\n",
        "pollutants_clean = [name.replace(\".\", \"_\") for name in pollutants]\n",
        "\n",
        "# Create aggregate expressions for mean and quantiles\n",
        "agg_exprs = []\n",
        "for col in pollutants_clean:\n",
        "    agg_exprs.extend([\n",
        "        mean(col).alias(f\"{col}_mean\"),\n",
        "        percentile_approx(col, 0.25).alias(f\"{col}_q25\"),\n",
        "        percentile_approx(col, 0.5).alias(f\"{col}_median\"),\n",
        "        percentile_approx(col, 0.75).alias(f\"{col}_q75\"),\n",
        "    ])\n",
        "\n",
        "# Time the operation\n",
        "start = time.time()\n",
        "\n",
        "df_stats = spark_df.groupBy(\"City\").agg(*agg_exprs)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# Show result\n",
        "df_stats.show(5, truncate=False)\n",
        "\n",
        "# Print time taken\n",
        "print(f\"⏱ Spark DataFrame API Time: {end - start:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WuqUF2Hj7OM",
        "outputId": "7032c110-213b-4942-dbba-4abe9541916c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+------+---------+------+------------------+-------+----------+-------+------------------+-------+----------+-------+------------------+-------+----------+-------+-----------------+------+---------+------+-----------------+---------+------------+---------+------------------+--------+-----------+--------+------------------+---------+----------+---------+\n",
            "|City    |CO_mean           |CO_q25|CO_median|CO_q75|CO2_mean          |CO2_q25|CO2_median|CO2_q75|NO2_mean          |NO2_q25|NO2_median|NO2_q75|SO2_mean          |SO2_q25|SO2_median|SO2_q75|O3_mean          |O3_q25|O3_median|O3_q75|PM2_5_mean       |PM2_5_q25|PM2_5_median|PM2_5_q75|PM10_mean         |PM10_q25|PM10_median|PM10_q75|AQI_mean          |AQI_q25  |AQI_median|AQI_q75  |\n",
            "+--------+------------------+------+---------+------+------------------+-------+----------+-------+------------------+-------+----------+-------+------------------+-------+----------+-------+-----------------+------+---------+------+-----------------+---------+------------+---------+------------------+--------+-----------+--------+------------------+---------+----------+---------+\n",
            "|Cairo   |293.81921675774134|198.0 |239.0    |316.0 |457.92039800995025|449.0  |454.0     |462.0  |32.617634335154676|18.9   |28.3      |41.2   |38.294319216757785|22.6   |29.6      |46.1   |61.10245901639344|37.0  |58.0     |84.0  |23.73605418943538|16.3     |20.7        |28.3     |43.4222222222221  |26.2    |34.9       |49.2    |52.48974458185358 |38.433334|51.65     |62.870003|\n",
            "|London  |187.74419398907105|156.0 |177.0    |205.0 |475.11442786069654|450.0  |458.0     |482.0  |21.797495446265863|10.5   |16.9      |28.8   |3.3260928961748655|1.4    |2.3       |4.0    |49.15403005464481|36.0  |51.0     |64.0  |9.985177595628416|5.3      |7.8         |12.5     |14.136008652094672|8.7     |11.9       |17.1    |27.097211959699365|20.8     |25.2      |30.33333 |\n",
            "|Sydney  |122.43078324225866|92.0  |109.0    |139.0 |443.19092039800995|437.0  |440.0     |446.0  |14.174567395264107|6.3    |11.4      |19.5   |5.617429417122051 |2.9    |4.8       |7.3    |46.14025500910747|28.0  |43.0     |59.0  |10.93517759562842|7.6      |10.2        |13.4     |17.424874772313366|11.8    |16.7       |22.1    |25.767748429360164|19.766666|23.89167  |29.049997|\n",
            "|Brasilia|221.4504781420765 |147.0 |192.0    |267.0 |445.72636815920396|440.0  |444.0     |450.0  |8.735632969034612 |2.5    |6.1       |12.4   |1.619854280510027 |0.9    |1.5       |2.1    |57.75728597449909|36.0  |55.0     |75.0  |6.549282786885226|3.3      |5.3         |8.5      |8.886725865209513 |4.6     |7.3        |11.5    |24.749358353756765|16.8     |22.975002 |30.8     |\n",
            "|Dubai   |440.46402550091074|305.0 |400.0    |533.0 |463.7786069651741 |452.0  |461.0     |473.0  |39.4882969034609  |23.5   |34.2      |51.1   |20.308970856101954|12.2   |17.4      |25.4   |93.87841530054645|57.0  |90.0     |118.0 |41.57414617486331|28.3     |39.2        |52.0     |111.04061930783287|58.7    |89.2       |143.4   |85.1137221584697  |67.30333 |78.10834  |98.86168 |\n",
            "+--------+------------------+------+---------+------+------------------+-------+----------+-------+------------------+-------+----------+-------+------------------+-------+----------+-------+-----------------+------+---------+------+-----------------+---------+------------+---------+------------------+--------+-----------+--------+------------------+---------+----------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "⏱ Spark DataFrame API Time: 0.0643 seconds\n"
          ]
        }
      ]
    }
  ]
}